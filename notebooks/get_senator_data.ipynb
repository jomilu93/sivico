{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84965b53",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mexican Senate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff8044",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3e2d92",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# importing required modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fdc5e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Senator Database, Exports to CSV in data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb27dd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Importing senator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819542dd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_senators():\n",
    "    senators_url = 'https://www.senado.gob.mx/65/datosAbiertos/senadoresDatosAb.json'\n",
    "    senators_json = requests.get(senators_url).json()\n",
    "    senators = pd.DataFrame.from_dict(senators_json)\n",
    "    senators = senators.rename(columns={\"idSenador\": \"senator_id\"})\n",
    "    return senators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6daef222",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "senators = get_senators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59dc21b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Creating a field that includes first and last names to join with initiatives+proposals table.\n",
    "senators[\"senadores\"] = senators[\"Nombre\"].str.strip()+\" \"+senators[\"Apellidos\"].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f4c529",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Importing attendance data and adding to senator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee10eb1a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_senator_attendance():\n",
    "    \n",
    "    senators = get_senators()\n",
    "    \n",
    "    senator_ids = senators[\"senator_id\"].tolist()\n",
    "    \n",
    "    senator_attendance = pd.DataFrame()\n",
    "    senator_attendance[\"senator_id\"] = \"\"\n",
    "    senator_attendance[\"session_date\"] = \"\"\n",
    "    senator_attendance[\"attendance_record\"] = \"\"\n",
    "\n",
    "    counter = 0\n",
    "    for sen in senator_ids:\n",
    "        url = f'https://www.senado.gob.mx/65/asistencias/{sen}#info'\n",
    "        html = requests.get(url)\n",
    "        content = BeautifulSoup(html.text, 'html.parser')\n",
    "        content_x = etree.HTML(str(content))\n",
    "        dates = content_x.xpath('//*[@id=\"imPage\"]/div[7]/div[2]/div/div[2]/section/div/div/table/tbody//a')\n",
    "        att_records = content_x.xpath('//*[@id=\"imPage\"]/div[7]/div[2]/div/div[2]/section/div/div/table/tbody//strong')\n",
    "        for i in range(len(dates)):\n",
    "            senator_attendance.at[i+counter, 'senator_id'] = sen\n",
    "            senator_attendance.at[i+counter, 'session_date'] = dates[i].text\n",
    "            senator_attendance.at[i+counter, 'attendance_record'] = att_records[i].text\n",
    "        counter += len(dates)\n",
    "\n",
    "    senator_attendance[\"attendance_score\"] = senator_attendance[\"attendance_record\"].copy()\n",
    "    senator_attendance[\"attendance_score\"] = senator_attendance[\"attendance_score\"].map(lambda x: 1 if x == \"Asistencia\" else 0)\n",
    "    senator_attendance = pd.merge(senator_attendance, senators[['senator_id','Fraccion', 'Estado', 'Apellidos', 'Nombre', 'tipoEleccion']], on='senator_id', how='left')\n",
    "\n",
    "    senator_attendance[\"full_name\"] = senator_attendance['Nombre'] + \" \" + senator_attendance['Apellidos']\n",
    "    \n",
    "    senator_attendance = senator_attendance.groupby(['senator_id', 'full_name', 'Fraccion', 'Estado', 'tipoEleccion'], as_index=False)[['attendance_score']].mean()\n",
    "\n",
    "    return senator_attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6ee014",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "senator_attendance = get_senator_attendance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd7a086",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "senators = senators.merge(senator_attendance[[\"senator_id\", \"attendance_score\"]], how=\"left\", on=\"senator_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e3618",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Importing initiatives and proposals, concatenating both and adding senator ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388f8dd3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_initiatives():\n",
    "    \"\"\"fucntion that extracts initiatives from Senate JSON.\"\"\"\n",
    "    \n",
    "    init_64_url = 'https://www.senado.gob.mx/65/datosAbiertos/iniciativa_64.json'\n",
    "    init_65_url = 'https://www.senado.gob.mx/65/datosAbiertos/iniciativa_65.json'\n",
    "    \n",
    "    init_64_json = requests.get(init_64_url).json()\n",
    "    init_65_json = requests.get(init_65_url).json()\n",
    "    \n",
    "    init_64 = pd.DataFrame.from_dict(init_64_json)\n",
    "    init_65 = pd.DataFrame.from_dict(init_65_json)\n",
    "    \n",
    "    initiatives = pd.concat([init_64, init_65])\n",
    "    \n",
    "    initiatives['fecha_presentacion'] = pd.to_datetime(initiatives['fecha_presentacion'],errors='coerce')\n",
    "    initiatives['fecha_aprobacion'] = pd.to_datetime(initiatives['fecha_aprobacion'],errors='coerce')\n",
    "    \n",
    "    initiatives = initiatives.set_index('id')\n",
    "        \n",
    "    return initiatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa36e10",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_proposals():\n",
    "    \"\"\"fucntion that extracts proposals from Senate JSON.\"\"\"\n",
    "    \n",
    "    prop_64_url = 'https://www.senado.gob.mx/65/datosAbiertos/proposicion_64.json'\n",
    "    prop_65_url = 'https://www.senado.gob.mx/65/datosAbiertos/proposicion_65.json'\n",
    "    \n",
    "    prop_64_json = requests.get(prop_64_url).json()\n",
    "    prop_65_json = requests.get(prop_65_url).json()\n",
    "    \n",
    "    prop_64 = pd.DataFrame.from_dict(prop_64_json)\n",
    "    prop_65 = pd.DataFrame.from_dict(prop_65_json)\n",
    "    \n",
    "    proposals = pd.concat([prop_64, prop_65])\n",
    "    \n",
    "    proposals['fecha_presentacion'] = pd.to_datetime(proposals['fecha_presentacion'],errors='coerce')\n",
    "    proposals['fecha_aprobacion'] = pd.to_datetime(proposals['fecha_aprobacion'],errors='coerce')\n",
    "    \n",
    "    proposals = proposals.set_index('id')\n",
    "    \n",
    "    return proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557b1ee1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s1/6jg25ryd59n_ggsp1fp4y47r0000gn/T/ipykernel_8874/846498830.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  initiatives['fecha_aprobacion'] = pd.to_datetime(initiatives['fecha_aprobacion'],errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "#Create concatenated df that includes initiatives and proposals.\n",
    "initiatives = get_initiatives()\n",
    "proposals = get_proposals()\n",
    "inipros = pd.concat([initiatives, proposals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8194ee0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inipros df has 9396 initiatives with 13 features.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inipros df has {inipros.shape[0]} initiatives with {inipros.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aaa02f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#creates a 1:1 relationship between initiative/proposal and senator (in case where more than 1 senator proposes).\n",
    "inipros[\"senadores\"] = inipros[\"senadores\"].apply(lambda x:x.strip().split(\"<br>\"))\n",
    "\n",
    "for i, row in inipros.iterrows():\n",
    "    senator_ids = []\n",
    "    for senator in row[\"senadores\"]:\n",
    "        strt_pos = senator.find('(')\n",
    "        senator = senator[:strt_pos-1].strip()\n",
    "        senator_ids.append(senator)\n",
    "    inipros.at[i, \"senadores\"] = senator_ids[:-1]\n",
    "\n",
    "inipros = inipros.explode(\"senadores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf07de1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Inner join on senator names to ensure only initiatives that match senator ids from table remain.\n",
    "inipros = inipros.merge(senators[[\"senadores\", \"senator_id\"]], how='inner', on='senadores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853e4c7a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inipros df has 7832 initiatives with 14 features.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inipros df has {inipros.shape[0]} initiatives with {inipros.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa6bff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add list of initiative strings back to senator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a67e84",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "senators[\"initiative_list\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d13916e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Function that creates a list of initiative syntheses and then adds to senator database.\n",
    "for i, row in senators.iterrows():\n",
    "    initiatives = []\n",
    "    relevant_inipros = inipros[inipros[\"senator_id\"] == str(row[\"senator_id\"])][\"sintesis\"]\n",
    "    [initiatives.append(initiative) for initiative in relevant_inipros]\n",
    "    senators.at[i, \"initiative_list\"] = initiatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb65405",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Creates dummy summary of a all initiatives, to be replaced by BERT or BETO summaries.\n",
    "senators[\"initatives_summary_dummy\"] = senators[\"initiative_list\"].copy()\n",
    "senators[\"initatives_summary_dummy\"] = senators[\"initatives_summary_dummy\"].apply(lambda x: \"\".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad985af",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Export file to CSV in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd991315",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_path = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_path)\n",
    "\n",
    "project_path = os.path.join(parent_directory, 'data')\n",
    "senators.to_csv(os.path.join(project_path, 'senators_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cf11d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classifying initiatives & proposals into topics with LDA (DEPRECATED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca4de7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## LDA Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372e5aa",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3988d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579bd67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clean(column):\n",
    "    \"\"\"Remove punctuation, make strings lower case, remove numbers. Tokenize, remove stopwords and lemmatize.\"\"\"\n",
    "    #Removing punctuation.\n",
    "    for punctuation in string.punctuation:\n",
    "        column = column.apply(lambda x: x.replace(punctuation, ''))\n",
    "    #Making lower case and removing whitespace.\n",
    "    column = column.apply(lambda x: x.lower().strip())\n",
    "    #Removing numbers\n",
    "    column = column.apply(lambda x: re.sub(r'[0-9]', '', x))\n",
    "    #Tokenize all rows.\n",
    "    column = column.apply(lambda x: word_tokenize(x))\n",
    "    #Remove stopwords and words too frequently present in initiative language.\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    stop_words_extra = (\"exhorta\", \"modificar\", \"actualizar\", \"política\", \"general\", \"caso\", \"derecho\", \"materia\", \"virtud\", \"referencias\", \"cambiar\", \"deberán\", \"día\", \"año\", \"denominación\", \"distrito\", \"cámara\", \"senadores\", \"normativa\", \"senado\", \"objetivo\", \"cumplimiento\", \"ordenamiento\", \"república\", \"reforma\", \"cada\", \"dar\", \"federal\", \"secretaría\", \"mención\", \"paso\", \"dejar\", \"principio\", \"ser\", \"paridad\", \"así\", \"derechos\", \"reformar\", \"propone\", \"nacional\", \"establecer\", \"méxico\", \"persona\", \"ley\", \"ciudad\", \"deberá\", \"legal\", \"personas\")\n",
    "    column = column.apply(lambda x: [w for w in x if w not in stop_words])\n",
    "    column = column.apply(lambda x: [w for w in x if w not in stop_words_extra])\n",
    "    # Lemmatizing the verbs\n",
    "    column = column.apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in x])\n",
    "    # 2 - Lemmatizing the nouns\n",
    "    column = column.apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in x])\n",
    "    # Rejoin words to make sentences\n",
    "    column = column.apply(lambda x: \" \".join(x))\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbb058",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inipros[\"sintesis_clean\"] = clean(inipros[\"sintesis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c992ee9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training vectorization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c5156",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c68098",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorized_text = vectorizer.fit_transform(inipros[\"sintesis_clean\"])\n",
    "\n",
    "# Instantiate the LDA \n",
    "n_components = 15\n",
    "lda_model = LatentDirichletAllocation(n_components=n_components)\n",
    "\n",
    "# Fit the LDA on the vectorized documents\n",
    "lda_model.fit(vectorized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac731705",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Visualize potential topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266749ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i]) for i in np.argsort(topic)[:-5 -1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc2a1c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a080b7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Test with real initiatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1aa12",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0, len(inipros))\n",
    "example = [inipros[\"sintesis\"][random_num]]\n",
    "example_df = pd.DataFrame(example, columns = [\"text\"])\n",
    "print(example_df[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3949c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clean_example = clean(example_df[\"text\"])\n",
    "example_vectorized = vectorizer.transform(clean_example)\n",
    "lda_vectors = lda_model.transform(example_vectorized)\n",
    "lda_vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
